# -*- coding: utf-8 -*-

__author__ = 'Daniele Marzetti and Felipè Matè'

"""Strutturale.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c8tOrPwYVjA7AZqIIqMm9nBrND98Y1QH
"""

"""# IMPORTS"""
import os
import pandas as pd
import numpy as np
from preprocessing import *
from cage import *
from lstm import *
from postprocessing_metrics import *


"""# MAIN"""

def main():
  # PREPROCESSING - DATASET

  # adapt_file_onehotencode
  case_ids, set_eventi, set_risorse, max_time, esistono_attributi = adapt_file_onehotencode(nome_file_ori, nome_file_mod, nome_file_onehotencoded)
  # create_dataset
  np_dataset = create_dataset(max_time, esistono_attributi, nome_file_onehotencoded)
  # preprocessing
  if esistono_attributi:
    case_ids2, matrice_attributi = preprocessing(case_ids, set_eventi, set_risorse, np_dataset, esistono_attributi, nome_file_preprocessed)
  else:
    case_ids2 = preprocessing(case_ids, set_eventi, set_risorse, np_dataset, esistono_attributi, nome_file_preprocessed)

  # IMPORT DATASET
  df=pd.read_csv(nome_file_preprocessed, sep=',',header=None)

  data = df.to_numpy()
  print(data.shape)
  
  #dataset split into train and test 
  datatrain, datatest, case_ids_train, case_ids_test = split_dataset(data, case_ids2, 0.7)

  #split label into train and test
  if esistono_attributi:
    matrice_attributi_train = matrice_attributi[:len(case_ids_train)]
    matrice_attributi_test = matrice_attributi[len(case_ids_train):]
    label_dataset_train = np.hstack((datatrain, matrice_attributi_train, np.reshape(np.array(case_ids_train), (len(np.array(case_ids_train)), 1))))
    label_dataset_test = np.hstack((datatest, matrice_attributi_test, np.reshape(np.array(case_ids_test), (len(np.array(case_ids_test)), 1))))
  else:
    label_dataset_train = np.hstack((datatrain, np.reshape(np.array(case_ids_train), (len(np.array(case_ids_train)), 1))))
    label_dataset_test = np.hstack((datatest, np.reshape(np.array(case_ids_test), (len(np.array(case_ids_test)), 1))))

  pd.DataFrame(label_dataset_train).to_csv("label_train.csv", index = False, header = False)
  pd.DataFrame(label_dataset_test).to_csv("label_test.csv", index = False, header = False)
  

  # ---------------
  # CAGE
  # ---------------

  #CAGE STRUTTURALE

  codifica = len(set_eventi)*3

  '''
  # Codifica [# attivita] + [# attivita] + [# attivita]
  # codifica = len(set_eventi)*3

  # Se esistono gli attributi
  # Codifica [# attivita] + [# attivita] + [# attivita] + [1 tempo] + [# risorse]
  #if esistono_attributi:	
  # codifica = codifica + 1 + len(set_risorse)
  '''

  dim_structural_embedding = 12
  # cage train
  CAGE_structural_train(codifica, dim_structural_embedding, datatrain, datatest)
  # cage test
  train_embeddings, test_embeddings, structural_decoder = CAGE_structural_test(datatrain, datatest)

  # save_embeddings
  save_embeddings(train_embeddings, test_embeddings, case_ids_train, case_ids_test, esistono_attributi, 0)

  #CAGE ATTRIBUTI
  if esistono_attributi:
    codifica = dim_structural_embedding + 1 + len(set_risorse)
    dim_embedding = dim_structural_embedding + 2

    new_datatrain = np.hstack((train_embeddings, matrice_attributi_train))
    new_datatest = np.hstack((test_embeddings, matrice_attributi_test))

    CAGE_attribute_train(codifica, dim_embedding, new_datatrain, datatest)
    train_embeddings, test_embeddings, attribute_decoder = CAGE_attribute_test(new_datatrain, new_datatest)

    # save_embeddings
    save_embeddings(train_embeddings, test_embeddings, case_ids_train, case_ids_test, esistono_attributi, 1)

  # ---------------
  # LSTM
  # ---------------

  nome_train_report = []
  input_train_report = []
  output_train_report = []

  nome_test_report = []
  input_test_report = []
  output_test_report = []

  attività_train = []
  input_train = []
  output_train = []

  attività_test = []
  input_test = []
  output_test = []

  attività_train_ji = []
  input_train_ji = []
  output_train_ji = []

  attività_test_ji = []
  input_test_ji = []
  output_test_ji = []

  for i in list_windows_size:
    log("------------------------------------------------------------------------------------------------------------------")
    log("DETAGLI: ")
    log("  window_size = " + str(i) + "  units = " + str(units_lstm) + "  threshold = " + str(threshold))
    log("")
    # lstm_preprocess
    log("ESECUZIONE: Preprocess")
    num_features, case_id, x_train, y_train, x_test, y_test = lstm_preprocess(i, lag, esistono_attributi)
    # lstm_model
    log("ESECUZIONE: Model")
    if esistono_attributi:
      train_predictions_decoder, test_predictions_decoder, train_label_predictions, test_label_predictions = lstm_model(i, units_lstm, num_features, x_train, y_train, x_test, y_test, lag, case_id, structural_decoder, attribute_decoder, label_dataset_train, label_dataset_test, esistono_attributi, set_risorse)
    else:
      train_predictions_decoder, test_predictions_decoder, train_label_predictions, test_label_predictions = lstm_model(i, units_lstm, num_features, x_train, y_train, x_test, y_test, lag, case_id, structural_decoder, None, label_dataset_train, label_dataset_test, esistono_attributi, set_risorse)

    # threshold_range
    log("ESECUZIONE: Threshold")
    threshold_range(train_predictions_decoder, test_predictions_decoder)
    # metrics_preprocess
    log("ESECUZIONE: Metrics preprocess")
    m_nome_train, m_input_train, m_output_train, l_m_nome_train, l_m_input_train, l_m_output_train, m_nome_test, m_input_test, m_output_test, l_m_nome_test, l_m_input_test, l_m_output_test = metrics_preprocess(threshold, train_predictions_decoder, test_predictions_decoder, train_label_predictions, test_label_predictions)
    # compute_metrics
    log("ESECUZIONE: Compute metrics")
    #se si vuole fare il plot anche dei valori della confusion matrix al variare della window size far ritornare dalla funzione compute_matrics le relative variabili e poi fare l'append nelle relative liste
    temp_nome_train_report, temp_input_train_report, temp_output_train_report, temp_nome_test_report, temp_input_test_report, temp_output_test_report, ji_nome_train, ji_input_train, ji_output_train, ji_nome_test, ji_input_test, ji_output_test = compute_metrics(m_nome_train, m_input_train, m_output_train, l_m_nome_train, l_m_input_train, l_m_output_train, 
               m_nome_test, m_input_test, m_output_test, l_m_nome_test, l_m_input_test, l_m_output_test, set_eventi, i)
    
    nome_train_report.append(temp_nome_train_report)
    nome_test_report.append(temp_nome_test_report)
    input_train_report.append(temp_input_train_report)
    input_test_report.append(temp_input_test_report)
    output_train_report.append(temp_output_train_report)
    output_test_report.append(temp_output_test_report)

    attività_train_ji.append(ji_nome_train)
    attività_test_ji.append(ji_nome_test)
    input_train_ji.append(ji_input_train)
    input_test_ji.append(ji_input_test)
    output_train_ji.append(ji_output_train)
    output_test_ji.append(ji_output_test)
    log("FINE")
    log("////////////////////////////////")

  # Plot line charts

  #disegna i grafici con i valori della confusion matrix per ogni classe al variare della window size
  #decommentare anche la relativa definizione se si vuole plottare tale metrica
  #plot_line_chart(attività_train, attività_test, input_train, input_test, output_train, output_test, set_eventi, list_windows_size)

  #disegna i grafici con i valori di precision, recall, f1-score per ogni classe (e la media) al variare della window size
  plot_line_chart_classification_report(nome_train_report, nome_test_report, input_train_report, input_test_report, output_train_report, output_test_report, set_eventi, list_windows_size)

  #disegna i grafici con i valori medi dell'indice di jaccard al variare del jaccard index
  plot_line_chart_ji(attività_train_ji, attività_test_ji, input_train_ji, input_test_ji, output_train_ji, output_test_ji, list_windows_size)


"""# RUN"""

# Nome file originale | modificato | one_hot_encoded | preprocessed
# nome_file_ori = "enriched_graph.txt"
nome_file_ori = "provvisorio.g"
nome_file_mod = "provvisorio_mod.g"
nome_file_onehotencoded = "onehotencoding.g"
nome_file_preprocessed = "preprocessed.csv"

# Lista con diversi windows size
list_windows_size = [2, 3, 4, 5, 6, 7, 10, 12, 15, 20]
# Numero posizione da predirre nel futuro
lag = 1
# Numero di neuroni nella LSTM per layer
units_lstm = 200
# Valore della soglia per le matrici
threshold = 0.2

os.mkdir('./risultati')
os.mkdir('./img')

main()
